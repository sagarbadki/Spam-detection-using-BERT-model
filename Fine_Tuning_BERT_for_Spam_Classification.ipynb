{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFOTiqrtNvyy"
   },
   "source": [
    "# Install Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4giRzM7NtHJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKd-Tj3hOMsZ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "cwJrQFQgN_BE",
    "outputId": "abd01694-ad2c-435d-8fff-da744e48303d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spamdata_v2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fzPPOrVQWiW5",
    "outputId": "78000c19-0309-47cb-d679-0a1e8195a7b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "676DPU1BOPdp",
    "outputId": "709fceb8-a311-41fb-8e8e-c05204824bc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfWnApvOoE7"
   },
   "source": [
    "# Split train dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfhSPF5jOWb7"
   },
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7hsdLoCO7uB"
   },
   "source": [
    "# Download BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1kY3gZjO2RE"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98081ddefd484ce3a7d309e5a05726ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55862b6dcfc4fcf91cb22b7d74eb934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1b708279ee46e8ba41d8e79db40dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wIYaWI_Prg8"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "yKwbpeN_PMiu",
    "outputId": "6feee42b-289a-4c78-f545-492645a67981"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcb85494d88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXcswEIRPvGe"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk5S7DWaP2t6"
   },
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wsm8bkRZQTw9"
   },
   "source": [
    "# Convert Integer Sequences to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR-lXwmzQPd6"
   },
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov1cOBlcRLuk"
   },
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUy9JKFYQYLp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2HZc5ZYRV28"
   },
   "source": [
    "# Freeze BERT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHZ0MC00RQA_"
   },
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7ahGBUWRi3X"
   },
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3iEtGyYRd0A"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBAJJVuJRliv"
   },
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "taXS0IilRn9J"
   },
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CDpoMQR_rK"
   },
   "source": [
    "# Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "izY5xH5eR7Ur",
    "outputId": "65859d7a-907e-4675-d954-03926197745a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57743559 3.72848948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass classes=[0 1], y=1188    0\n",
      "5403    0\n",
      "2924    0\n",
      "880     1\n",
      "719     0\n",
      "       ..\n",
      "5121    0\n",
      "1006    1\n",
      "4374    1\n",
      "903     0\n",
      "5057    0\n",
      "Name: label, Length: 3900, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1WvfY2vSGKi"
   },
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "# weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "My4CA0qaShLq"
   },
   "source": [
    "# Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rskLk8R_SahS"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    batch = [r for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGXovFDlSxB5"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KZEgxRRTLXG"
   },
   "source": [
    "# Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k1USGTntS3TS",
    "outputId": "abc8dfa5-00da-44db-a345-de683be3cf3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.362\n",
      "Validation Loss: 0.225\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.285\n",
      "Validation Loss: 0.184\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.232\n",
      "Validation Loss: 0.173\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.301\n",
      "Validation Loss: 0.200\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.215\n",
      "Validation Loss: 0.152\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.151\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.218\n",
      "Validation Loss: 0.167\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.183\n",
      "Validation Loss: 0.150\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.178\n",
      "Validation Loss: 0.130\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.226\n",
      "Validation Loss: 0.128\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yrhUc9kTI5a"
   },
   "source": [
    "# Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OacxUyizS8d1",
    "outputId": "791547d2-43f5-43e1-e630-953035d89826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4SVftkkTZXA"
   },
   "source": [
    "# Get Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZl0SZmFTRQA"
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq, test_mask)\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Ms1ObHZxTYSI",
    "outputId": "9651a4de-3f9a-4556-9ae1-50b2d51aa2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       724\n",
      "           1       0.84      0.94      0.89       112\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.92      0.95      0.93       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "YqzLS7rHTp4T",
    "outputId": "7dbad87a-2c14-46a4-d426-f4663273d79b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      704   20\n",
       "1        7  105"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpX1uTwjUPY6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine-Tuning BERT for Spam Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
